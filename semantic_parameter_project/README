semantic_parameter_project/
│
├── data/                      # (可选) 存放原始数据和处理后的中间数据
│   ├── semantic_source.xlsx   # 示例：原始 Excel 数据文件
│   └── prepared_data.csv      # 示例：预处理后的 CSV 数据文件
│
├── vector_store/              # 存放向量数据库的持久化文件
│   ├── chroma_db_semantic_final/ # ChromaDB 数据库目录
│   ├── embeddings.npy         # 保存生成的嵌入向量
│   └── metadata_for_index.csv # 保存与嵌入向量对应的元数据
│
├── src/                       # 存放项目核心源代码的目录
│   ├── __init__.py            # 标记 src 为一个 Python 包
│   ├── config.py              # 配置文件，集中管理路径、模型名、列名等
│   ├── data_processor.py      # 负责数据加载和预处理的模块
│   ├── embedding_generator.py # 负责生成文本嵌入向量的模块
│   ├── vector_store_manager.py # 负责与向量数据库交互的模块
│   ├── search_service.py      # 封装核心搜索查询逻辑的模块
│   └── utils.py               # (可选) 存放通用辅助函数，如计时器、日志记录等
│
├── scripts/                   # 存放可执行脚本/程序的目录
│   ├── __init__.py            # 标记 scripts 为一个 Python 包 (可选)
│   ├── build_knowledge_base.py # 用于运行完整知识库构建流程的脚本
│   └── run_query_app.py        # 用于运行交互式命令行查询应用的脚本
│
├── requirements.txt           # 列出项目所需的所有 Python 依赖库及其版本
└── README.md                  # 项目说明文件，包含安装、使用指南等信息



语义参数知识库项目使用指南本指南将引导您完成项目的设置、知识库构建和查询应用的运行。1. 环境准备获取代码: 确保您已将之前提供的所有 .py 代码文件保存在本地，并按照指定的目录结构组织好（包含 src/ 和 scripts/ 目录等）。创建目录:在项目根目录下手动创建 data/ 和 vector_store/ 文件夹。准备原始数据:将包含参数信息的原始 Excel 文件（例如 semantic_source.xlsx）放入项目根目录下的 data/ 文件夹中。重要: 确认 src/config.py 文件中的 EXCEL_FILE_PATH 和 SHEET_NAMES 配置与您的实际文件和工作表名称一致。安装 Python 依赖:打开您的终端或命令行工具。导航到项目的根目录（即包含 src, scripts, requirements.txt 的目录）。(如果还没有 requirements.txt) 运行以下命令安装必要的库：pip install pandas numpy sentence-transformers chromadb scikit-learn openpyxl tabulate
(推荐) 创建 requirements.txt 文件，内容类似如下（版本号可能需要根据您的环境调整）：pandas>=1.0.0
numpy>=1.18.0
sentence-transformers>=2.0.0
chromadb>=0.4.0 # 请使用您安装的 chromadb 版本
scikit-learn>=0.24.0
openpyxl>=3.0.0 # 用于读取 .xlsx 文件
tabulate>=0.8.0 # 用于 data_processor.py 的美观打印 (可选)
然后可以通过 pip install -r requirements.txt 安装。2. 构建知识库 (首次运行或数据更新后运行)目的: 此步骤将执行数据处理、生成嵌入向量，并将它们存入向量数据库以供查询。操作:在终端或命令行中，确保您位于项目的根目录下。运行以下命令：python scripts/build_knowledge_base.py
说明:该脚本会按顺序调用 DataProcessor, EmbeddingGenerator, 和 VectorStoreManager 中的方法。首次运行时，EmbeddingGenerator 需要下载预训练的 Sentence Transformer 模型 (paraphrase-multilingual-mpnet-base-v2)，这可能需要一些时间，具体取决于您的网络速度。模型下载后会缓存，后续运行会快很多。整个过程（特别是嵌入生成）可能需要几分钟到更长时间，具体取决于您的数据量和机器性能。成功执行后，您会在 data/ 目录下看到 prepared_data.csv，在 vector_store/ 目录下看到 embeddings.npy, metadata_for_index.csv 以及 chroma_db_semantic_final/ 数据库文件。何时运行:首次设置项目时必须运行一次。当您的原始 Excel 数据文件 (data/semantic_source.xlsx) 内容发生更改后，需要重新运行此脚本来更新知识库。3. 运行查询应用目的: 启动一个交互式的命令行界面，让您可以输入参数类型和值进行语义查询。操作:在终端或命令行中，确保您位于项目的根目录下。运行以下命令：python scripts/run_query_app.py
交互:程序启动后会显示欢迎信息和示例。按照提示依次输入“参数类型”和“参数值”。系统会根据您的输入进行语义搜索，并显示最相关的结果，包括标准值、代码、匹配的实际写法以及相似度距离（距离越小越相似）。输入 q 可以退出查询应用。按 Ctrl+C 也可以中断程序。总结:准备环境: 安装依赖，准备数据。构建知识库: 运行 python scripts/build_knowledge_base.py (首次或数据更新后)。开始查询: 运行 python scripts/run_query_app.py。按照这些步骤操作，您就可以成功使用这个语义参数知识库查询系统了。